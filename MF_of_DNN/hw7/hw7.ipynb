{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematical Foundations on Deep Neural Network\n",
    "## Homework #7\n",
    "### 2017-11362 박건도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![prob1.png](prob1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![prob2.png](prob2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![prob3](prob3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![prob4](prob4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![prob5](prob5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![prob6](prob6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lr = 0.001\n",
    "batch_size = 100\n",
    "epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "'''\n",
    "Step 1:\n",
    "'''\n",
    "\n",
    "# MNIST dataset\n",
    "dataset = datasets.MNIST(root='../data/mnist_data/',\n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(dataset, [50000, 10000])\n",
    "\n",
    "test_dataset = datasets.MNIST(root='../data/mnist_data/',\n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "# KMNIST dataset, only need test dataset\n",
    "anomaly_dataset = datasets.KMNIST(root='../data/kmnist_data/',\n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor(),\n",
    "                              download=True)\n",
    "\n",
    "# print(len(train_dataset))  # 50000\n",
    "# print(len(validation_dataset))  # 10000\n",
    "# print(len(test_dataset))  # 10000\n",
    "# print(len(anomaly_dataset))  # 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 2: AutoEncoder\n",
    "'''\n",
    "# Define Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 32)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        z = F.relu(self.fc3(x))\n",
    "        return z\n",
    "\n",
    "# Define Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(32, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 784)\n",
    "    def forward(self, z):\n",
    "        z = F.relu(self.fc1(z))\n",
    "        z = F.relu(self.fc2(z))\n",
    "        x = torch.sigmoid(self.fc3(z))  # to make output's pixels are 0~1\n",
    "        x = x.view(x.size(0), 1, 28, 28) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 3: Instantiate model & define loss and optimizer\n",
    "'''\n",
    "enc = Encoder().to(device)\n",
    "dec = Decoder().to(device)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(list(enc.parameters()) + list(dec.parameters()), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th epoch starting.\n",
      "1th epoch starting.ing batch #499 reconstruction loss: 0.029653\n",
      "2th epoch starting.ing batch #499 reconstruction loss: 0.022749\n",
      "3th epoch starting.ing batch #499 reconstruction loss: 0.019026\n",
      "4th epoch starting.ing batch #499 reconstruction loss: 0.014858\n",
      "5th epoch starting.ing batch #499 reconstruction loss: 0.014297\n",
      "6th epoch starting.ing batch #499 reconstruction loss: 0.012640\n",
      "7th epoch starting.ing batch #499 reconstruction loss: 0.012427\n",
      "8th epoch starting.ing batch #499 reconstruction loss: 0.011287\n",
      "9th epoch starting.ing batch #499 reconstruction loss: 0.010938\n",
      "Time ellapsed in training is: 33.234450817108154 loss: 0.010582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAi0UlEQVR4nO3de3QV1d3/8ffXcAkS8MJFkKhAiyJaBRtRwSJaL6C2UmtbKY+iVhF/WutdauvlWf21i1bbZf0ptXip2uqDtYraQr0gKt4xKKIgKiI8pCIGlHATSML398eekEPOJJyEzDnh5PNa66zM7Jk5Z2+M55O9Z2aPuTsiIiJ17ZLrCoiISMukgBARkVgKCBERiaWAEBGRWAoIERGJpYAQEZFYCgiRepjZv81sbHPv28g6DDezsuZ+X5FMtMl1BUSak5mtS1ndFdgEVEfrF7r7g5m+l7uPTGJfkZ2FAkLyirsX1Syb2RLgfHefUXc/M2vj7lXZrJvIzkZDTNIq1AzVmNm1ZvYZ8Bcz28PM/mVm5Wb2ZbRcnHLMC2Z2frR8jpm9bGa3RPt+YmYjm7hvHzObZWZrzWyGmd1hZn/LsB0HRp+12szmm9l3U7adbGYLovf9j5ldFZV3jdq22sy+MLOXzEz/78t26ZdEWpMewJ7AfsA4wu//X6L1fYGvgNsbOP4I4AOgK/A74B4zsybs+xAwG+gC3ASclUnlzawt8E/gGaA78FPgQTM7INrlHsIwWifgYGBmVH4lUAZ0A/YCrgM0x45slwJCWpMtwI3uvsndv3L3Ve7+qLtvcPe1wK+BYxo4fqm73+Xu1cD9QE/CF27G+5rZvsDhwA3uvtndXwaezLD+RwJFwMTo2JnAv4DR0fZKYICZdXb3L939rZTynsB+7l7p7i+5JmGTDCggpDUpd/eNNStmtquZ/dnMlprZGmAWsLuZFdRz/Gc1C+6+IVosauS+ewNfpJQBLMuw/nsDy9x9S0rZUqBXtPx94GRgqZm9aGZHReU3A4uAZ8xssZlNyPDzpJVTQEhrUvev5iuBA4Aj3L0zMCwqr2/YqDksB/Y0s11TyvbJ8NhPgX3qnD/YF/gPgLu/6e6nEYafHgf+HpWvdfcr3b0v8B3gCjP79o41Q1oDBYS0Zp0I5x1Wm9mewI1Jf6C7LwVKgZvMrF30V/53Mjz8DWA9cI2ZtTWz4dGxU6L3GmNmu7l7JbCG6PJeMzvVzL4enQOpKa+O/QSRFAoIac1uBToAK4HXgaey9LljgKOAVcD/BR4m3K/RIHffDHwXGEmo8yTgbHdfGO1yFrAkGi4bD/xXVN4PmAGsA14DJrn7C83VGMlfpnNVIrllZg8DC9098R6MSGOoByGSZWZ2uJl9zcx2MbMRwGmEcwYiLYrupBbJvh7AY4T7IMqAi9z97dxWSSSdhphERCSWhphERCRWXg0xde3a1Xv37p3raoiI7DTmzJmz0t27xW3Lq4Do3bs3paWlua6GiMhOw8yW1rdNQ0wiIhJLASEiIrEUECIiEiuvzkGISMtUWVlJWVkZGzdu3P7OkojCwkKKi4tp27ZtxscoIEQkcWVlZXTq1InevXtT/zOWJCnuzqpVqygrK6NPnz4ZH6chJhFJ3MaNG+nSpYvCIUfMjC5dujS6B6eAEJGsUDjkVlP+/RUQAL/6FTz9dK5rISLSoiggAH77W3jmmVzXQkQSsmrVKgYOHMjAgQPp0aMHvXr12rq+efPmBo8tLS3l0ksv3e5nDBkypFnq+sILL3Dqqac2y3vtKJ2kBmjfHjZt93ktIrKT6tKlC3PnzgXgpptuoqioiKuuumrr9qqqKtq0if86LCkpoaSkZLuf8eqrrzZLXVsS9SBAASHSCp1zzjlcccUVHHvssVx77bXMnj2bIUOGMGjQIIYMGcIHH3wAbPsX/U033cR5553H8OHD6du3L7fddtvW9ysqKtq6//DhwznjjDPo378/Y8aMoWbW7OnTp9O/f3+OPvpoLr300u32FL744gtGjRrFIYccwpFHHsm8efMAePHFF7f2gAYNGsTatWtZvnw5w4YNY+DAgRx88MG89NJLO/xvpB4EhIDQ9dki2XHZZRD9Nd9sBg6EW29t9GEffvghM2bMoKCggDVr1jBr1izatGnDjBkzuO6663j00UfTjlm4cCHPP/88a9eu5YADDuCiiy5Ku7fg7bffZv78+ey9994MHTqUV155hZKSEi688EJmzZpFnz59GD169Hbrd+ONNzJo0CAef/xxZs6cydlnn83cuXO55ZZbuOOOOxg6dCjr1q2jsLCQyZMnc9JJJ/GLX/yC6upqNmzY0Oh/j7oUEACFhepBiLRCP/jBDygoKACgoqKCsWPH8tFHH2FmVFZWxh5zyimn0L59e9q3b0/37t1ZsWIFxcXF2+wzePDgrWUDBw5kyZIlFBUV0bdv3633IYwePZrJkyc3WL+XX355a0gdd9xxrFq1ioqKCoYOHcoVV1zBmDFjOP300ykuLubwww/nvPPOo7KyklGjRjFw4MAd+acBFBCBhphEsqcJf+knpWPHjluXr7/+eo499limTp3KkiVLGD58eOwx7du337pcUFBAVVVVRvs05eFscceYGRMmTOCUU05h+vTpHHnkkcyYMYNhw4Yxa9Yspk2bxllnncXVV1/N2Wef3ejPTKVzEKCAEBEqKiro1asXAPfdd1+zv3///v1ZvHgxS5YsAeDhhx/e7jHDhg3jwQcfBMK5ja5du9K5c2c+/vhjvvGNb3DttddSUlLCwoULWbp0Kd27d+eCCy7gJz/5CW+99dYO11k9CFBAiAjXXHMNY8eO5Q9/+APHHXdcs79/hw4dmDRpEiNGjKBr164MHjx4u8fcdNNNnHvuuRxyyCHsuuuu3H///QDceuutPP/88xQUFDBgwABGjhzJlClTuPnmm2nbti1FRUU88MADO1znvHomdUlJiTfpgUEnnADr10MeXqYm0hK8//77HHjggbmuRs6tW7eOoqIi3J2LL76Yfv36cfnll2ft8+P+O5jZHHePvY5XQ0wAbdtCPSekRESay1133cXAgQM56KCDqKio4MILL8x1lRqkISaAXXaBLVtyXQsRyXOXX355VnsMO0o9CICCAqiuznUtRPJaPg1n74ya8u+vgAAFhEjCCgsLWbVqlUIiR2qeB1FYWNio4zTEBCEgNMQkkpji4mLKysooLy/PdVVarZonyjWGAgLCOQj1IEQS07Zt20Y9yUxaBg0xgYaYRERiKCBAASEiEkMBAToHISISQwEBOgchIhJDAQEaYhIRiaGAAAWEiEgMBQRoqg0RkRgKCFAPQkQkhgICFBAiIjEUEKDLXEVEYiQaEGY2wsw+MLNFZjYhZvsYM5sXvV41s0MzPbZZ6TJXEZE0iQWEmRUAdwAjgQHAaDMbUGe3T4Bj3P0Q4FfA5EYc23x0klpEJE2SPYjBwCJ3X+zum4EpwGmpO7j7q+7+ZbT6OlCc6bHNapddQNMQi4hsI8mA6AUsS1kvi8rq8xPg34091szGmVmpmZU2eSphM/UgRETqSDIgLKYs9s90MzuWEBDXNvZYd5/s7iXuXtKtW7cmVRQz9SBEROpI8nkQZcA+KevFwKd1dzKzQ4C7gZHuvqoxxzYbBYSISJokexBvAv3MrI+ZtQPOBJ5M3cHM9gUeA85y9w8bc2yzUkCIiKRJrAfh7lVmdgnwNFAA3Ovu881sfLT9TuAGoAswycwAqqLhothjk6qrAkJEJF2ijxx19+nA9Dpld6Ysnw+cn+mxibG4Ux4iIq2b7qSG2oBQL0JEZCsFBIT7IEABISKSQgEBtT0I3QshIrKVAgI0xCQiEkMBAQoIEZEYCghQQIiIxFBAgAJCRCSGAgIUECIiMRQQoIAQEYmhgADdByEiEkMBAboPQkQkhgICNMQkIhJDAQEKCBGRGAoIUECIiMRQQIACQkQkhgICFBAiIjEUEKCAEBGJoYAA3QchIhJDAQG6D0JEJIYCAjTEJCISQwEBCggRkRgKCFBAiIjEUECAAkJEJIYCAhQQIiIxFBCggBARiaGAAN0HISISQwEBug9CRCSGAgI0xCQiEkMBAQoIEZEYCghQQIiIxFBAgAJCRCSGAgIUECIiMRQQoIAQEYmhgIDa+yB0mauIyFYKCFAPQkQkRqIBYWYjzOwDM1tkZhNitvc3s9fMbJOZXVVn2xIze9fM5ppZaZL1VECIiKRrk9Qbm1kBcAdwAlAGvGlmT7r7gpTdvgAuBUbV8zbHuvvKpOq4lQJCRCRNkj2IwcAid1/s7puBKcBpqTu4++fu/iZQmWA9tk8BISKSJsmA6AUsS1kvi8oy5cAzZjbHzMbVt5OZjTOzUjMrLS8vb1pNFRAiImmSDAiLKWvMN/BQdz8MGAlcbGbD4nZy98nuXuLuJd26dWtKPRUQIiIxkgyIMmCflPVi4NNMD3b3T6OfnwNTCUNWyVBAiIikSTIg3gT6mVkfM2sHnAk8mcmBZtbRzDrVLAMnAu8lVlMFhIhImsSuYnL3KjO7BHgaKADudff5ZjY+2n6nmfUASoHOwBYzuwwYAHQFplr44m4DPOTuTyVVVwWEiEi6xAICwN2nA9PrlN2ZsvwZYeiprjXAoUnWbRsKCBGRNLqTGhQQIiIxFBCggBARiaGAAAWEiEgMBQQoIEREYiggQAEhIhJDAQEKCBGRGAoIUECIiMRQQIACQkQkhgICFBAiIjEUEKCAEBGJoYAABYSISAwFBCggRERiKCBAASEiEiOjgIiez7BLtLy/mX3XzNomW7UsUkCIiKTJtAcxCyg0s17Ac8C5wH1JVSrrFBAiImkyDQhz9w3A6cD/c/fvER7skx8UECIiaTIOCDM7ChgDTIvKEn3YUFYpIERE0mQaEJcBPwemRo8N7Qs8n1itsk0BISKSJqNegLu/CLwIEJ2sXunulyZZsaxSQIiIpMn0KqaHzKyzmXUEFgAfmNnVyVYtixQQIiJpMh1iGuDua4BRwHRgX+CspCqVdQoIEZE0mQZE2+i+h1HAE+5eCeTPt6kCQkQkTaYB8WdgCdARmGVm+wFrkqpU1ikgRETSZHqS+jbgtpSipWZ2bDJVygEFhIhImkxPUu9mZn8ws9Lo9XtCbyI/KCBERNJkOsR0L7AW+GH0WgP8JalKZZ0CQkQkTaZ3Q3/N3b+fsv7fZjY3gfrkhgJCRCRNpj2Ir8zs6JoVMxsKfJVMlXJAASEikibTHsR44AEz2y1a/xIYm0yVckABISKSJtOrmN4BDjWzztH6GjO7DJiXYN2yRwEhIpKmUU+Uc/c10R3VAFckUJ/cUECIiKTZkUeOWrPVItcUECIiaXYkIPLn21QBISKSpsFzEGa2lvggMKBDIjXKBQWEiEiaBgPC3TtlqyI5pYAQEUmzI0NM+UMBISKSJtGAMLMRZvaBmS0yswkx2/ub2WtmtsnMrmrMsc1c0fBTASEislViAWFmBcAdwEhgADDazAbU2e0L4FLgliYc25yVDT8VECIiWyXZgxgMLHL3xe6+GZgCnJa6g7t/7u5vApWNPbZZKSBERNIkGRC9gGUp62VRWbMea2bjaqYhLy8vb1JFFRAiIumSDIi4G+ky/QbO+Fh3n+zuJe5e0q1bt4wrt+2nKSBEROpKMiDKgH1S1ouBT7NwbOMpIERE0iQZEG8C/cysj5m1A84EnszCsY2ngBARSZPpdN+N5u5VZnYJ8DRQANzr7vPNbHy0/U4z6wGUAp2BLdEMsQOi2WLTjk2qrgoIEZF0iQUEgLtPB6bXKbszZfkzwvBRRscmRgEhIpJGd1KDAkJEJIYCAhQQIiIxFBCggBARiaGAgNqAKCvLbT1ERFoQBQTUBsQNN+S2HiIiLYgCAmoDQkREtlJAiIhILAUEqAchIhJDAQGwS8o/w/r1uauHiEgLooCAbXsQK1bkrh4iIi2IAgJgjz1ql5cuzV09RERaEAUEQGFh7fJxx+WuHiIiLYgCIs4nn+S6BiIiOaeAiNO3LyxcmOtaiIjklAKiPjoXISKtnAKixqGHbru+ZUtu6iEi0kIoIGrMnLnt+sknQ48euamLiEgLoICoseee6WW6J0JEWjEFhIiIxFJApBo+PL1sw4asV0NEpCVQQKS64IL0svffz349RERaAAVEqjZt0stKStSLEJFWSQGRasiQ+PI5c7JbDxGRFkABkaq4GNxh6NBty3VPhIi0QgqIOI88su36U0/lph4iIjmkgIjTsyc8+2zt+sSJuauLiEiOKCDqc/zx267//Oe5qYeISI4oIBrSqVPtsnoRItLKKCAasmZNrmsgIpIzCojGOPPMXNdARCRrFBDbk3qT3MMP564eIiJZpoDYng4dtl3/9NPc1ENEJMsUEJkoLKxd7tUrd/UQEckiBUQmXnhh23WznFRDRCSbFBCZiAsE3RchInku0YAwsxFm9oGZLTKzCTHbzcxui7bPM7PDUrYtMbN3zWyumZUmWc/tOvzw9DLdFyEieS5mfuvmYWYFwB3ACUAZ8KaZPenuC1J2Gwn0i15HAH+KftY41t1XJlXHjGlISURaoSR7EIOBRe6+2N03A1OA0+rscxrwgAevA7ubWc8E69S8zGDmzFzXQkQkEUkGRC9gWcp6WVSW6T4OPGNmc8xsXH0fYmbjzKzUzErLy8ubodr16N4dRo1KL//2t5P7TBGRHEoyIOLGZbwR+wx198MIw1AXm9mwuA9x98nuXuLuJd26dWt6bbdnxQqYOhXOOSd927p1yX2uiEiOJBkQZcA+KevFQN27zOrdx91rfn4OTCUMWeXepEnpZZ06QUVF9usiIpKgJAPiTaCfmfUxs3bAmcCTdfZ5Ejg7uprpSKDC3ZebWUcz6wRgZh2BE4H3Eqxr5jp0gI0b08s1sZ+I5JnEAsLdq4BLgKeB94G/u/t8MxtvZuOj3aYDi4FFwF3A/4nK9wJeNrN3gNnANHdvOY91a98e6p7vOP/83NRFRCQh5l73tMDOq6SkxEtLs3TLhDvsUidfly6FfffNzueLiDQDM5vj7iVx23QndVOZpT+7un//3NRFRCQBCogdccYZcMABtetffQVz5+asOiIizUkBsaMm1JlBZNAguP12+PDD3NRHRKSZKCB2VNx9ET/9aehZmMG112a9SiIizUEB0RyOO67+bb/7XfbqISLSjBQQzWHGjIa3m4VzE1u2ZKU6IiLNQQHRHMzghBMavopp0CC4+GKYPTt79RIR2QG6D6K5ZTI1eM39EpWV0KaNphMXkZzRfRDZlEkPYb/94JNPoF07uOee5OskItIECojmVlICv/nN9vfr2zf8vPJK2Lw59CIuvDDZuomINIICormZ1T6v+phjtr//mjVhbieAyZPD8RddBK+9FsqWLQvTeoiIZJkCIimffQZPPQW/+hX89a9wxBHbP6bGnXfCkCFw6KHhXMUFF+gKKBHJOp2kzpbp0+GUU3b8faqq4PPPw7mLa64JJ7nrThooIpIhnaRuCU4+GebP3/H3adMG9t4brr8+DE0VFMC0abBoEey5J3z00Y5/hogICojsGjAgnE/YvBl+8IPQq2gOp54K/frBl1+GIa3//Cfcd3HJJeF8xttvw6pVUF3dPJ8nIq2Chphagh/+MAwbvfhi8p9VXR2GpN57L4RKzQnyCy4I50yWLUu+DiLSYjQ0xNQm25WRGH//e/hZXQ0ff7ztFOLNraBg2/Wf/Sz0MGbNCut9+8Jzz0GfPvHHL1sGPXuGoS4RyWvqQbRECxZAaSkUFcH3v5+bOnTuHHoYxx8fphD54Q/D8y66dg2z1e6+e7jKqm791q+Hjh1zUmURabyGehAKiJ3JG2+EIaENG+Cf/4SJE+Huu3P7POzFi+Hss0OgpJ5T+fOfYdy42vV160LwDR6c/TqKSL0UEPnIHZYvD1c0nXEGPPoo3HZb+Ov+pZdg2LBc17DWNdeEK7imTYOFC+HrX08f6hKRnFBA5LuqKti0aduhnWefDZMCDh0KBx5YOyHg4sW103zk0sSJIdj+8Q+4+upw4nzLltDT2HXXsI/Oc4gkTgEh6dzD+YK//AVeeAEeeyyca1i4MNc121bbtuF8x5gxYXht4kRYvToE4DHHwI9/DOPHh3M2gweHhzftvnvt8Q8/DMceC92756gBIi2bAkKaZvny8Bf9/vuHKT8KC3euZ23vs0/tZbvjxsGtt4bA2bIl9KgqK2HOHNhrr9DG+sydG/4djj46G7UWySoFhDSv1auhoiKc/2jbNpR9/evhEt2//hXOOiun1dshF10Ef/pTGPp6/HH49rfh3HO33ee110J4TpsGo0eHsr32goMP3v77V1fD7beHmXsLC2vL3cNL06ZIlikgJLuqq+GVV8IQ0NNPw4knhi+/l14Kl8WuXBm+XJcsCU/Zy1f771/b43rooXC/ycyZodcCcMcdIVj32CMM8U2cGIK3c+fwbzR9OowYEYbH1q0Llz2LNDMFhLQclZUhQFL/eq6ogPLy8GX69tvwy19Cjx5hRlyp35VXwu9/D8XF4ebK554LFyCYwaefhgdS9esXppHv2zdcSbZgQTiXc9JJIaAffBDGjoVOncK+GzeGHtIxx4TezKZNYWqYFStCmL3zTjhX1b592LegIHzeggVwyCHx9Zw2LVwokcnFEevXh/dM/f2QRCkgZOeyYUO4kmn16nDC2T2ESps2YbmyMnxxrVsH//u/0KEDdOkSvtBGjAh3h++1V3hw069/Hb7QevbMdatalz32CBcH/OY3tc9q//hjGDUK3n039J6+973wR8HKleE1fvy27/H734fgueUWmDQp/C786Efhqr2KijA5ZdeuYf3228M5or59Q3jNnBnmKLvhBjj99DA3WY25c+FrXwu/TwUF4XeqbdsQmLvtFn6Xqqoyv4quqir8rNl/7twQiDXT2DRFZWU4f5aFKw4bCgjcPW9e3/zmN10kVkWF+4YN25Zt2uS+YIH78ce7P/FEbXlVlfuMGe633OK+fr37xx+7Dxnifvrp7mec4X7++e6vvFJz1kCvfH3tvrt7YaH7mDHp2375y+0f//jj7h995H7ffWH9hBPcv/Ut988+C79nNfvdf797ebn7Y4+5X3ed+5o17j16hG2PPOI+erT7nDnuL74Yjps0yb1dO/fqavc33nBfudK9rKzJ/2sApe7x36nqQYjsqM8+Cz2cXr3Cenk53HVXOBG9YkX4y/Sgg+Daa8NltxD+Il6wIExlcs01YUhojz3C1VbXXx8eGPXqq7Wf0a5dGOoRqU8Tv8s1xCTSUqxdG4bQ9tqr4f3c4Zln4IQTGr6yadOm8AyQu++GP/4RpkwJTy/s3Tu8xy67hPMTN94YLhg44IAwvNKzZ+3d9jfeCA88AEcdFYKuJsQgnHM4/HCF085AAdEwBYRIjrnXni+qrg5j/KtXhzH1bt3CjZhFReES6enTw3mDjh1DaH75Zbh3ZfXqcOJ7jz3CeYlx48I5qQMPDO9fWRl6ZYcdFgLyb38LPa6qqhCMEHpuM2aE93rttXAV2SOPhOloXnopvd4FBaG+3/lOOGdy882129q3D5+Tul9du+4a2pBLCoiGKSBEWpGaXk27drmtR12rVoUT3dXVIejq9gCrq0OYPfEEDB8eLmO+5x741rfCpdGzZ4cwGzs2nGzv3TtckHHEEWHCzpISmDcP9tsP1qwJwXDooSGAm0ABISIisfRMahERaTQFhIiIxFJAiIhIrEQDwsxGmNkHZrbIzCbEbDczuy3aPs/MDsv0WBERSVZiAWFmBcAdwEhgADDazAbU2W0k0C96jQP+1IhjRUQkQUn2IAYDi9x9sbtvBqYAp9XZ5zTggeiO79eB3c2sZ4bHiohIgpIMiF7AspT1sqgsk30yORYAMxtnZqVmVlpeXr7DlRYRkSDJgLCYsro3XdS3TybHhkL3ye5e4u4l3Zp4o4iIiKRL8qnwZcA+KevFwKcZ7tMug2PTzJkzZ6WZLW1SbaErsLKJx+6s1Ob819raC2pzY+1X34YkA+JNoJ+Z9QH+A5wJ/LjOPk8Cl5jZFOAIoMLdl5tZeQbHpnH3JnchzKy0vrsJ85XanP9aW3tBbW5OiQWEu1eZ2SXA00ABcK+7zzez8dH2O4HpwMnAImADcG5DxyZVVxERSZdkDwJ3n04IgdSyO1OWHYh9KHHcsSIikj26k7rW5FxXIAfU5vzX2toLanOzyavZXEVEpPmoByEiIrEUECIiEqvVB0Q+TQpoZvea2edm9l5K2Z5m9qyZfRT93CNl28+jdn9gZiellH/TzN6Ntt1mZnE3LrYIZraPmT1vZu+b2Xwz+1lUnpftNrNCM5ttZu9E7f3vqDwv25vKzArM7G0z+1e0ntdtNrMlUV3nmllpVJbdNrt7q30RLqH9GOhLuDnvHWBAruu1A+0ZBhwGvJdS9jtgQrQ8AfhttDwgam97oE/071AQbZsNHEW4o/3fwMhct62BNvcEDouWOwEfRm3Ly3ZHdSuKltsCbwBH5mt767T9CuAh4F+t5Hd7CdC1TllW29zaexB5NSmgu88CvqhTfBpwf7R8PzAqpXyKu29y908I96IMjiZL7Ozur3n47Xog5ZgWx92Xu/tb0fJa4H3CvF152W4P1kWrbaOXk6ftrWFmxcApwN0pxXnd5npktc2tPSAynhRwJ7aXuy+H8GUKdI/KG5oosSymvMUzs97AIMJf1Xnb7mioZS7wOfCsu+d1eyO3AtcAW1LK8r3NDjxjZnPMbFxUltU2J3qj3E4g40kB89AOT5TYkphZEfAocJm7r2lgmHWnb7e7VwMDzWx3YKqZHdzA7jt9e83sVOBzd59jZsMzOSSmbKdqc2Sou39qZt2BZ81sYQP7JtLm1t6DyGRCwZ3diqibSfTz86i8vraXRct1y1ssM2tLCIcH3f2xqDjv2+3uq4EXgBHkd3uHAt81syWEYeDjzOxv5HebcfdPo5+fA1MJQ+JZbXNrD4itEwqaWTvCpIBP5rhOze1JYGy0PBZ4IqX8TDNrb2FSxH7A7KjbutbMjoyudjg75ZgWJ6rjPcD77v6HlE152W4z6xb1HDCzDsDxwELytL0A7v5zdy92996E/0dnuvt/kcdtNrOOZtapZhk4EXiPbLc512fqc/0iTBb4IeGs/y9yXZ8dbMv/AMuBSsJfDj8BugDPAR9FP/dM2f8XUbs/IOXKBqAk+mX8GLid6I77lvgCjiZ0mecBc6PXyfnabuAQ4O2ove8BN0TlednemPYPp/YqprxtM+HKynei1/ya76Zst1lTbYiISKzWPsQkIiL1UECIiEgsBYSIiMRSQIiISCwFhIiIxFJAiETMbF30s7eZ/biZ3/u6OuuvNuf7iyRBASGSrjfQqIAws4Lt7LJNQLj7kEbWSSTrFBAi6SYC34rm4b88mhzvZjN708zmmdmFAGY23MKzKB4C3o3KHo8mV5tfM8GamU0EOkTv92BUVtNbsei934vm7P9Rynu/YGb/MLOFZvZgzTz+ZjbRzBZEdbkl6/860mq09sn6ROJMAK5y91MBoi/6Cnc/3MzaA6+Y2TPRvoOBgz1MsQxwnrt/EU2D8aaZPeruE8zsEncfGPNZpwMDgUOBrtExs6Jtg4CDCHPnvAIMNbMFwPeA/u7uNdNuiCRBPQiR7TsRODuaYvsNwnQH/aJts1PCAeBSM3sHeJ0weVo/GnY08D/uXu3uK4AXgcNT3rvM3bcQphDpDawBNgJ3m9npwIYdbJtIvRQQIttnwE/dfWD06uPuNT2I9Vt3ClNRHw8c5e6HEuZMKszgveuzKWW5Gmjj7lWEXsujhAe/PNWIdog0igJCJN1awuNLazwNXBRNK46Z7R/NsFnXbsCX7r7BzPoTHgVao7Lm+DpmAT+KznN0Izw2dnZ9FYuee7Gbu08HLiMMT4kkQucgRNLNA6qioaL7gD8Shnfeik4UlxP/2MangPFmNo8wo+brKdsmA/PM7C13H5NSPpXwvOB3CLPSXuPun0UBE6cT8ISZFRJ6H5c3qYUiGdBsriIiEktDTCIiEksBISIisRQQIiISSwEhIiKxFBAiIhJLASEiIrEUECIiEuv/A2eiHMfuacSGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Step 4: Training\n",
    "'''\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "for epoch in range(epochs) :\n",
    "    print(\"{}th epoch starting.\".format(epoch))\n",
    "    enc.train()\n",
    "    dec.train()\n",
    "    for batch, (images, _) in enumerate(train_loader) :\n",
    "        images = images.to(device)\n",
    "        z = enc(images)\n",
    "        reconstructed_images = dec(z)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss = loss_function(images, reconstructed_images)\n",
    "        train_loss.backward()\n",
    "        train_loss_list.append(train_loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"[Epoch {epoch:3d}] Processing batch #{batch:3d} reconstruction loss: {train_loss.item():.6f}\", end='\\r')\n",
    "end = time.time()\n",
    "print(\"Time ellapsed in training is: {}\".format(end - start))\n",
    "\n",
    "# plotting train loss\n",
    "plt.plot(range(1,len(train_loss_list)+1), train_loss_list, 'r', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('loss.png')\n",
    "\n",
    "enc.eval()\n",
    "dec.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:  22.62565851211548\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step 5: Calculate standard deviation by using validation set\n",
    "'''\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=batch_size)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for images, _ in validation_loader:\n",
    "    images = images.to(device)\n",
    "    z = enc(images)\n",
    "    recon = dec(z)\n",
    "    test = (images - recon)**2\n",
    "    score = ((images - recon)**2).sum((1,2,3))\n",
    "    scores.append(score.cpu().detach().numpy())\n",
    "mean = np.mean(scores)\n",
    "std = np.std(scores)\n",
    "\n",
    "threshold = mean + 3 * std\n",
    "print(\"threshold: \", threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly: 108, type I error: 1.08%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step 6: Anomaly detection (mnist)\n",
    "'''\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size)\n",
    "\n",
    "anomaly, n = 0, 0\n",
    "\n",
    "for images, _ in test_loader:\n",
    "    images = images.to(device)\n",
    "    n += images.shape[0]\n",
    "    z = enc(images)\n",
    "    recon = dec(z)\n",
    "    score = ((images - recon)**2).sum((1,2,3))\n",
    "    anomaly += torch.sum(score > threshold)\n",
    "print(f'anomaly: {anomaly.item()}, type I error: {anomaly / n * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly: 9756, type II error: 2.44%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step 7: Anomaly detection (kmnist)\n",
    "'''\n",
    "anomaly_loader = torch.utils.data.DataLoader(dataset=anomaly_dataset, batch_size=batch_size)\n",
    "\n",
    "anomaly, n = 0, 0\n",
    "\n",
    "for images, _ in anomaly_loader:\n",
    "    images = images.to(device)\n",
    "    n += images.shape[0]\n",
    "    z = enc(images)\n",
    "    recon = dec(z)\n",
    "    score = ((images - recon)**2).sum((1,2,3))\n",
    "    anomaly += torch.sum(score > threshold)\n",
    "print(f'anomaly: {anomaly.item()}, type II error: {100 - anomaly / n * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
