---
title: 
  - 회귀분석 및 실습 HW14
author: 
  - 서울대학교 통계학과 2017-11362 박건도
date: "`r format(Sys.time(), '%Y년 %m월 %d일')`"
header-includes:
  - \usepackage[hangul]{kotex}
output:
  pdf_document:
    fig_caption: yes
    latex_engine: xelatex
    df_print: kable
mainfont: NanumBarunGothic
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(0)
```

```{r libraries, include=FALSE}
library(dplyr)
library(ggplot2)
library(ROCR)
```

# IRIS data
```{r logistic}
# data processing
iris_df <- iris
iris_df[,"Species"] <- as.factor(ifelse(iris_df[, "Species"] == "setosa", 1, 0))

#split train - test set
idx <- 1:150 %in% sample.int(150, 105) # 70:30
iris_train <- iris_df[idx, ]
iris_test <- iris_df[!idx, ]

# logistic regression
result <- glm(Species ~ ., data = iris_train, family = "binomial",
              control = glm.control(maxit = 30))
summary(result)

# train accuracy with cutoff = 0.5
prob <- predict(result, iris_train, type = "response")
pred <- prediction(prob, iris_train$Species)
perf <- performance(pred, measure = "acc")
perf@y.values[[1]][max(which(perf@x.values[[1]] >= 0.5))]

# train auc
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf)
performance(pred, measure = "auc")@y.values[[1]]

# test accuracy
prob <- predict(result, iris_test, type = "response")
pred <- prediction(prob, iris_test$Species)
perf <- performance(pred, measure = "acc")
perf@y.values[[1]][max(which(perf@x.values[[1]] >= 0.5))]

# test auc
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf)
performance(pred, measure = "auc")@y.values[[1]]
```

# 2. num of Awards
```{r poisson}
# data processing
p <- read.csv("https://stats.idre.ucla.edu/stat/data/poisson_sim.csv")
p <- within(p, {
  prog <- factor(prog, levels=1:3, labels=c("General", "Academic", "Vocational"))
  id <- factor(id)
})

# split train - test set
idx <- 1:200 %in% sample.int(200, 140) # 70 : 30
p_train <- p[idx,]
p_test <- p[!idx,]

# poisson regression
m1 <- glm <- glm(num_awards ~ prog + math, family = "poisson", data = p_train)
summary(m1)

# train accuracy with cutoff = 0.5
prob <- predict(m1, p_train, type = "response")
sum(round(prob) == p_train$num_awards) / length(prob)

# train MSE
sum((prob - p_train$num_awards)^2) / length(prob)

# test accuracy with cutoff = 0.5
prob <- predict(m1, p_test, type = "response")
sum(round(prob) == p_test$num_awards) / length(prob)

# test MSE
sum((prob - p_test$num_awards)^2) / length(prob)

#plot
p$phat <- predict(m1, p, type = "response")
ggplot(p, aes(x = math, y = phat, color = prog)) +
  geom_point(aes(y = num_awards), alpha = 0.5, position = position_jitter(h=.2))+
  geom_line(size = 1)+
  theme_bw()+
  labs(x = "Math score", y = "Expected number of awards")
```
